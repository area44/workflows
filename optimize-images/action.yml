name: area44/optimize-images
description: "Automatically optimize images (JPG, JPEG, PNG, WebP)"

inputs:
  node-version:
    description: "Node.js version to use"
    required: false
    default: 22

outputs:
  optimizedCount:
    description: "Number of images optimized"
    value: ${{ steps.optimize.outputs.optimizedCount }}
  skippedCount:
    description: "Number of images skipped"
    value: ${{ steps.optimize.outputs.skippedCount }}
  totalSaved:
    description: "Total KB saved"
    value: ${{ steps.optimize.outputs.totalSaved }}
  details:
    description: "Per-file optimization comparison"
    value: ${{ steps.optimize.outputs.details }}

runs:
  using: "composite"
  steps:
    - name: Setup Node.js
      uses: actions/setup-node@v6
      with:
        node-version: ${{ inputs.node-version }}

    - name: Install dependencies
      shell: bash
      run: |
        cd "$RUNNER_TEMP"
        npm init -y >/dev/null 2>&1
        npm install --no-save sharp globby

    - name: Optimize images
      id: optimize
      shell: bash
      run: |
        mkdir -p "$RUNNER_TEMP/originals"

        cat <<'EOF' > "$RUNNER_TEMP/optimize-images.mjs"
        import fs from 'fs';
        import path from 'path';
        import { globby } from 'globby';
        const sharp = (await import('sharp')).default;
        import crypto from 'crypto';

        const paths = await globby(['**/*.{jpg,jpeg,png,webp}'], { gitignore: true });

        let optimizedCount = 0;
        let skippedCount = 0;
        let totalSaved = 0;
        let details = [];

        const originalsDir = process.env.RUNNER_TEMP + '/originals';
        const hashes = {};

        for (const file of paths) {
          const content = fs.readFileSync(file);
          const hash = crypto.createHash('sha256').update(content).digest('hex');
          hashes[file] = hash;

          const backupPath = path.join(originalsDir, file);
          fs.mkdirSync(path.dirname(backupPath), { recursive: true });
          fs.writeFileSync(backupPath, content);
        }

        for (const file of paths) {
          const input = fs.readFileSync(file);
          const originalSizeKB = input.length / 1024;

          let pipeline = sharp(input).rotate();

          if (file.match(/\.(jpe?g)$/i)) {
            pipeline = pipeline.jpeg({ quality: 80, mozjpeg: true });
          } else if (file.match(/\.png$/i)) {
            pipeline = pipeline.png({ compressionLevel: 9 });
          } else if (file.match(/\.webp$/i)) {
            pipeline = pipeline.webp({ quality: 80 });
          }

          const optimizedBuffer = await pipeline.toBuffer();
          const optimizedHash = crypto.createHash('sha256').update(optimizedBuffer).digest('hex');

          if (optimizedHash === hashes[file]) {
            skippedCount++;
            details.push(\`\${file}: no improvement\`);
          } else {
            fs.writeFileSync(file, optimizedBuffer);
            const savedKB = (input.length - optimizedBuffer.length) / 1024;
            totalSaved += savedKB;
            optimizedCount++;
            details.push(\`\${file}: \${originalSizeKB.toFixed(1)} KB â†’ \${(optimizedBuffer.length / 1024).toFixed(1)} KB (saved \${savedKB.toFixed(1)} KB)\`);
          }
        }

        const output = (name, value) => {
          if (value && value.includes('\\n')) {
            const delimiter = \`EOF_\${name}\`;
            fs.appendFileSync(
              process.env.GITHUB_OUTPUT,
              \`\${name}<<\${delimiter}\\n\${value}\\n\${delimiter}\\n\`
            );
          } else {
            fs.appendFileSync(process.env.GITHUB_OUTPUT, \`\${name}=\${value}\\n\`);
          }
        };

        output("optimizedCount", optimizedCount.toString());
        output("skippedCount", skippedCount.toString());
        output("totalSaved", totalSaved.toFixed(1));
        output("details", details.join('\\n'));
        EOF

        node "$RUNNER_TEMP/optimize-images.mjs"
